{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. imports\n",
    "import time, numpy as np, pandas as pd, torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from scripts.magix.dynamic import nnSTModule, nnMTModule  # MAGI-X NN module\n",
    "from scripts.magix.inference import FMAGI                 # MAGI-X inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. UQ metric utilities\n",
    "\n",
    "# ---------- UQ metric helpers ----------\n",
    "def interp_truth_to(t_truth, X_truth, t_eval):\n",
    "    D = X_truth.shape[1]\n",
    "    X_eval = np.column_stack([np.interp(t_eval, t_truth, X_truth[:, d]) for d in range(D)])\n",
    "    return X_eval\n",
    "\n",
    "def percentile_band(samples, alpha=0.10):\n",
    "    lo = np.percentile(samples, 100*(alpha/2), axis=0)\n",
    "    hi = np.percentile(samples, 100*(1 - alpha/2), axis=0)\n",
    "    return lo, hi\n",
    "\n",
    "def coverage_and_width(samples, t_full, t_truth, X_truth, t_end_fit, alpha=0.10):\n",
    "    \"\"\"\n",
    "    samples: (N, T, D)  stochastic trajectories (e.g., MC-dropout)\n",
    "    t_full:  (T,)       time grid of samples (initial point included)\n",
    "    t_truth: (T0,)      truth grid\n",
    "    X_truth: (T0,D)     truth values\n",
    "    \"\"\"\n",
    "    X_eval = interp_truth_to(t_truth, X_truth, t_full)  # (T,D)\n",
    "    lo, hi = percentile_band(samples, alpha=alpha)      # (T,D)\n",
    "    width  = hi - lo\n",
    "    inside = (X_eval >= lo) & (X_eval <= hi)\n",
    "\n",
    "    fit_mask = t_full <= t_end_fit\n",
    "    fct_mask = ~fit_mask\n",
    "\n",
    "    def summarize(mask):\n",
    "        cov   = inside[mask].mean()\n",
    "        w     = width[mask].mean()\n",
    "        # normalized width: divide per-dim by dynamic range in the region\n",
    "        Xm    = X_eval[mask]\n",
    "        rng   = Xm.max(axis=0) - Xm.min(axis=0)\n",
    "        rng[rng == 0] = 1.0\n",
    "        w_norm = (width[mask].mean(axis=0) / rng).mean()\n",
    "        return cov, w, w_norm\n",
    "\n",
    "    cov_fit, w_fit, wN_fit = summarize(fit_mask)\n",
    "    cov_fct, w_fct, wN_fct = summarize(fct_mask)\n",
    "\n",
    "    # per-dim breakdown (handy for appendix tables)\n",
    "    per_dim = []\n",
    "    D = X_truth.shape[1]\n",
    "    for d in range(D):\n",
    "        pdict = dict(\n",
    "            cov_fit = inside[fit_mask, d].mean(),\n",
    "            cov_fct = inside[fct_mask, d].mean(),\n",
    "            w_fit   = width[fit_mask, d].mean(),\n",
    "            w_fct   = width[fct_mask, d].mean(),\n",
    "        )\n",
    "        per_dim.append(pdict)\n",
    "\n",
    "    return dict(\n",
    "        lo=lo, hi=hi, X_eval=X_eval,\n",
    "        coverage_fit=cov_fit, coverage_fct=cov_fct,\n",
    "        width_fit=w_fit, width_fct=w_fct,\n",
    "        width_norm_fit=wN_fit, width_norm_fct=wN_fct,\n",
    "        per_dim=per_dim\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) MC-dropout sampler for MAGI-X\n",
    "\n",
    "# ---------- MC-dropout sampler ----------\n",
    "def mc_dropout_samples(model, fOde, trecon, xinfer, N=50):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      t_full: (T,)\n",
    "      samples: (N, T, D)\n",
    "    \"\"\"\n",
    "    # keep dropout ON\n",
    "    fOde.train()\n",
    "    x0 = xinfer[0, :].squeeze()\n",
    "\n",
    "    # one deterministic call to fix t_full and T\n",
    "    tr1, xr1 = model.predict(trecon[1:], trecon[:1], x0, random=True)\n",
    "    t_full = np.concatenate([trecon[:1], tr1])\n",
    "    D = xr1.shape[1]\n",
    "    T = t_full.size\n",
    "\n",
    "    # collect stochastic draws (dropout is active)\n",
    "    draws = np.empty((N, T, D), dtype=float)\n",
    "    draws[0] = np.vstack([x0.reshape(1, -1), xr1])\n",
    "\n",
    "    for i in range(1, N):\n",
    "        tri, xri = model.predict(trecon[1:], trecon[:1], x0, random=True)\n",
    "        draws[i] = np.vstack([x0.reshape(1, -1), xri])\n",
    "\n",
    "    return t_full, draws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) ODEs + truth simulators (FN / LV (log) / Hes1)\n",
    "\n",
    "# ---------- Dynamics ----------\n",
    "def FN(y, t, a, b, c):\n",
    "    V, R = y\n",
    "    dVdt = c * (V - V**3/3.0 + R)\n",
    "    dRdt = -1.0/c * (V - a + b*R)\n",
    "    return (dVdt, dRdt)\n",
    "\n",
    "def LV_log(y, t, a, b, c, d):\n",
    "    # state in log-space\n",
    "    x1, x2 = np.exp(y)\n",
    "    dx1dt = a*x1 - b*x1*x2\n",
    "    dx2dt = c*x1*x2 - d*x2\n",
    "    return [dx1dt/x1, dx2dt/x2]  # chain rule\n",
    "\n",
    "def Hes1(y, t, a, b, c, d, e, f, g):\n",
    "    P, M, H = y\n",
    "    dPdt = -a*P*H + b*M - c*P\n",
    "    dMdt = -d*M + e/(1 + P**2)\n",
    "    dHdt = -a*P*H + f/(1 + P**2) - g*H\n",
    "    return (dPdt, dMdt, dHdt)\n",
    "\n",
    "# ---------- Truth simulators ----------\n",
    "def simulate_FN():\n",
    "    a, b, c = 0.2, 0.2, 3.0\n",
    "    V0, R0 = -1.0, 1.0\n",
    "    t = np.linspace(0, 40, 1281)\n",
    "    X = odeint(FN, (V0, R0), t, args=(a, b, c))\n",
    "    return t, X\n",
    "\n",
    "def simulate_LV_log():\n",
    "    a, b, c, d = 1.5, 1.0, 1.0, 3.0\n",
    "    x1_0, x2_0 = 5.0, 0.2\n",
    "    y0 = np.log([x1_0, x2_0])\n",
    "    t = np.linspace(0, 12, 321)\n",
    "    Y = odeint(LV_log, y0, t, args=(a, b, c, d))  # log-state\n",
    "    X = np.column_stack([np.exp(Y[:,0]), np.exp(Y[:,1])])  # back to original scale\n",
    "    return t, X\n",
    "\n",
    "def simulate_Hes1():\n",
    "    a, b, c, d, e, f, g = 0.022, 0.3, 0.031, 0.028, 0.5, 20.0, 0.3\n",
    "    P0, M0, H0 = 1.438575, 2.037488, 17.90385\n",
    "    t = np.linspace(0, 640, 1281)\n",
    "    X = odeint(Hes1, (P0, M0, H0), t, args=(a, b, c, d, e, f, g))\n",
    "    return t, X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Observation maker (same style you used)\n",
    "\n",
    "def make_observations(t, X, no_train, noise, seed=0):\n",
    "    \"\"\"\n",
    "    t: (T,), X: (T,D)\n",
    "    noise: list-like of length D (std dev per component)\n",
    "    returns: list of arrays [(n_i, 2) ...] with columns (t, y_obs)\n",
    "    and the last observation time (fit boundary).\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    T, D = X.shape\n",
    "    # observe first half of the horizon unless you change obs_idx\n",
    "    obs_idx = np.linspace(0, (T-1)//2, no_train).astype(int)\n",
    "    obs = []\n",
    "    for d in range(D):\n",
    "        tobs = t[obs_idx].copy()\n",
    "        yobs = X[obs_idx, d].copy() + np.random.normal(0, noise[d], size=no_train)\n",
    "        obs.append(np.c_[tobs, yobs])\n",
    "    t_end_fit = max(o[:,0].max() for o in obs)\n",
    "    return obs, t_end_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) One-system pipeline (fit → samples → metrics)\n",
    "\n",
    "def run_system(system_name,\n",
    "               simulate_fn,\n",
    "               nn_hidden=512,\n",
    "               grid_size=161,\n",
    "               max_epoch=2500,\n",
    "               lr=1e-3,\n",
    "               dropout_p=0.1,\n",
    "               N_train=41,\n",
    "               noise=None,\n",
    "               seed=188714368,\n",
    "               N_samples=50):\n",
    "    \"\"\"\n",
    "    Returns a dict with metrics + a small table row for the paper.\n",
    "    \"\"\"\n",
    "    # 1) truth & observations\n",
    "    t_truth, X_truth = simulate_fn()\n",
    "    D = X_truth.shape[1]\n",
    "    if noise is None: noise = [0.1]*D\n",
    "    obs, t_end_fit = make_observations(t_truth, X_truth, N_train, noise, seed=seed)\n",
    "\n",
    "    # 2) fit MAGI-X (MT = multi-task)\n",
    "    torch.manual_seed(seed)\n",
    "    fOde = nnMTModule(D, [nn_hidden], dp=dropout_p)\n",
    "    model = FMAGI(obs, fOde, grid_size=grid_size, interpolation_orders=3)\n",
    "\n",
    "    # inference (MAP trajectory)\n",
    "    trecon = t_truth[np.linspace(0, t_truth.size-1, 321).astype(int)]\n",
    "    _, xinfer = model.map(max_epoch=max_epoch,\n",
    "                          learning_rate=lr, decay_learning_rate=True,\n",
    "                          hyperparams_update=False, dynamic_standardization=True,\n",
    "                          verbose=False, returnX=True)\n",
    "\n",
    "    # 3) MC-dropout samples\n",
    "    t_full, samples = mc_dropout_samples(model, fOde, trecon, xinfer, N=N_samples)\n",
    "\n",
    "    # 4) metrics\n",
    "    m = coverage_and_width(samples, t_full, t_truth, X_truth, t_end_fit, alpha=0.10)\n",
    "\n",
    "    # 5) compact rows for paper table\n",
    "    row_fit = dict(system=system_name, region='fit',\n",
    "                   coverage_90=m['coverage_fit'], width=m['width_fit'], width_norm=m['width_norm_fit'],\n",
    "                   N_samples=N_samples, T=t_full.size, D=D, N_train=N_train)\n",
    "    row_fct = dict(system=system_name, region='forecast',\n",
    "                   coverage_90=m['coverage_fct'], width=m['width_fct'], width_norm=m['width_norm_fct'],\n",
    "                   N_samples=N_samples, T=t_full.size, D=D, N_train=N_train)\n",
    "\n",
    "    return dict(metrics=m, t_full=t_full, samples=samples, obs=obs,\n",
    "                t_truth=t_truth, X_truth=X_truth,\n",
    "                rows=[row_fit, row_fct])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Orchestrator: run FN / LV / Hes1 and print a paper-ready table\n",
    "def run_all_systems(save_csv_path=None):\n",
    "    # You can tweak N_train and noise per system to match your experiments\n",
    "    jobs = [\n",
    "        dict(name='FN',   sim=simulate_FN,     N_train=41,  noise=[0.1, 0.1]),\n",
    "        dict(name='LV',   sim=simulate_LV_log, N_train=41,  noise=[0.1, 0.1]),\n",
    "        dict(name='Hes1', sim=simulate_Hes1,   N_train=81,  noise=[0.1, 0.1, 0.1]),\n",
    "    ]\n",
    "    rows = []\n",
    "    per_system = {}\n",
    "    for jb in jobs:\n",
    "        out = run_system(jb['name'], jb['sim'],\n",
    "                         N_train=jb['N_train'], noise=jb['noise'],\n",
    "                         dropout_p=0.1, N_samples=50,\n",
    "                         nn_hidden=512, grid_size=161, max_epoch=2500, lr=1e-3)\n",
    "        rows.extend(out['rows'])\n",
    "        per_system[jb['name']] = out  # keep everything (for plots)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # nice formatting for paper\n",
    "    df_display = df.copy()\n",
    "    df_display['coverage_90'] = (100*df_display['coverage_90']).map(lambda x: f\"{x:5.1f}%\")\n",
    "    df_display['width']       = df_display['width'].map(lambda x: f\"{x:.3f}\")\n",
    "    df_display['width_norm']  = df_display['width_norm'].map(lambda x: f\"{x:.3f}\")\n",
    "\n",
    "    # order columns\n",
    "    df_display = df_display[['system','region','coverage_90','width','width_norm','N_train','N_samples','T','D']]\n",
    "\n",
    "    print(\"\\n=== Coverage@90% and Band Width (Fit vs Forecast) ===\")\n",
    "    print(df_display.to_string(index=False))\n",
    "\n",
    "    if save_csv_path:\n",
    "        df.to_csv(save_csv_path, index=False)\n",
    "        print(f\"\\n[Saved raw metrics to {save_csv_path}]\")\n",
    "\n",
    "    return df, per_system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Coverage@90% and Band Width (Fit vs Forecast) ===\n",
      "system   region coverage_90              width         width_norm  N_train  N_samples   T  D\n",
      "    FN      fit       66.7%              0.166              0.054       41         50 322  2\n",
      "    FN forecast       92.5%              0.288              0.097       41         50 322  2\n",
      "    LV      fit       94.8%           2044.380            298.722       41         50 322  2\n",
      "    LV forecast       70.3% 96930221511194.078 14135303168782.176       41         50 322  2\n",
      "  Hes1      fit       90.3%              3.403              0.419       81         50 322  3\n",
      "  Hes1 forecast       95.6%              8.297              0.990       81         50 322  3\n",
      "\n",
      "[Saved raw metrics to uq_metrics_fn_lv_hes1.csv]\n"
     ]
    }
   ],
   "source": [
    "df_metrics, out = run_all_systems(save_csv_path=\"uq_metrics_fn_lv_hes1.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
